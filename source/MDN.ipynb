{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from loader import train_loader, val_loader, test_loader, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureDensityForecastNet(nn.Module):\n",
    "    def __init__(self, window_size, num_series, static_dim, latent_dim=128, \n",
    "                 n_mixtures=3, dropout=0.1, output_dim=2):\n",
    "        \"\"\"\n",
    "        - window_size: số bước lịch sử.\n",
    "        - num_series: số biến trong chuỗi (ví dụ: 2 cho Units và Revenue).\n",
    "        - static_dim: số đặc trưng ngoại lai.\n",
    "        - latent_dim: kích thước tầng ẩn của mạng FC.\n",
    "        - n_mixtures: số thành phần hỗn hợp (mixture components).\n",
    "        - output_dim: số biến dự báo (2).\n",
    "        \n",
    "        Đầu vào của mô hình là: flatten(x_seq) concat static_features.\n",
    "        Kích thước đầu vào = window_size * num_series + static_dim.\n",
    "        Output của mạng là các tham số của hỗn hợp Gaussian:\n",
    "          - pi: mixing coefficients (n_mixtures)\n",
    "          - mu: trung bình (n_mixtures x output_dim)\n",
    "          - sigma: độ lệch chuẩn (n_mixtures x output_dim)\n",
    "        Tổng output dimension = n_mixtures*(1 + 2*output_dim).\n",
    "        \"\"\"\n",
    "        super(MixtureDensityForecastNet, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.num_series = num_series\n",
    "        self.static_dim = static_dim\n",
    "        self.input_dim = window_size * num_series + static_dim\n",
    "        self.n_mixtures = n_mixtures\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(latent_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        # Final layer: outputs n_mixtures*(1+2*output_dim)\n",
    "        self.fc_out = nn.Linear(latent_dim, n_mixtures * (1 + 2 * output_dim))\n",
    "    \n",
    "    def forward(self, x_seq, x_cal):\n",
    "        # x_seq: (batch, window_size, num_series)\n",
    "        # x_cal: (batch, static_dim)\n",
    "        batch_size = x_seq.size(0)\n",
    "        x_seq_flat = x_seq.view(batch_size, -1)  # (batch, window_size*num_series)\n",
    "        x_input = torch.cat([x_seq_flat, x_cal], dim=1)  # (batch, input_dim)\n",
    "        h = self.fc(x_input)\n",
    "        out = self.fc_out(h)\n",
    "        # Reshape out: (batch, n_mixtures, 1+2*output_dim)\n",
    "        out = out.view(batch_size, self.n_mixtures, 1 + 2 * self.output_dim)\n",
    "        # Tách các tham số:\n",
    "        pi = out[:, :, 0]  # (batch, n_mixtures)\n",
    "        mu = out[:, :, 1:1+self.output_dim]  # (batch, n_mixtures, output_dim)\n",
    "        sigma = out[:, :, 1+self.output_dim:]  # (batch, n_mixtures, output_dim)\n",
    "        # Xử lý các tham số:\n",
    "        pi = torch.softmax(pi, dim=1)\n",
    "        sigma = torch.exp(sigma)  # đảm bảo sigma > 0\n",
    "        return pi, mu, sigma\n",
    "\n",
    "def mdn_loss(pi, mu, sigma, y_true):\n",
    "    \"\"\"\n",
    "    Tính negative log-likelihood cho hỗn hợp Gaussian.\n",
    "    - pi: (batch, n_mixtures)\n",
    "    - mu: (batch, n_mixtures, output_dim)\n",
    "    - sigma: (batch, n_mixtures, output_dim)\n",
    "    - y_true: (batch, output_dim)\n",
    "    \"\"\"\n",
    "    batch_size, n_mixtures, output_dim = mu.shape\n",
    "    # Mở rộng y_true thành shape (batch, n_mixtures, output_dim)\n",
    "    y_true = y_true.unsqueeze(1).expand_as(mu)\n",
    "    \n",
    "    # Tính probability density của từng thành phần Gaussian (giả sử độc lập các biến)\n",
    "    # density = 1/(sqrt(2pi)*sigma) * exp(-0.5*((y - mu)/sigma)^2)\n",
    "    exp_term = -0.5 * (((y_true - mu) / sigma) ** 2)\n",
    "    coef = 1.0 / (np.sqrt(2 * np.pi) * sigma)\n",
    "    component_prob = coef * torch.exp(exp_term)  # (batch, n_mixtures, output_dim)\n",
    "    \n",
    "    # Tính product theo output_dim (với giả sử độc lập)\n",
    "    component_prob = torch.prod(component_prob, dim=2)  # (batch, n_mixtures)\n",
    "    \n",
    "    # Tính tổng có trọng số theo pi\n",
    "    weighted_prob = pi * component_prob  # (batch, n_mixtures)\n",
    "    prob = torch.sum(weighted_prob, dim=1)  # (batch)\n",
    "    \n",
    "    # Negative log likelihood\n",
    "    nll = -torch.log(prob + 1e-8)  # tránh log(0)\n",
    "    return torch.mean(nll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MixtureDensityForecastNet(window_size=30, num_series=2, static_dim=18,\n",
    "                                  latent_dim=64, n_mixtures=3,\n",
    "                                  dropout=0.1, output_dim=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "kl_start = 0.0\n",
    "kl_max = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated at epoch 1 with validation loss 1.2891\n",
      "Best model updated at epoch 2 with validation loss 0.9108\n",
      "Best model updated at epoch 3 with validation loss 0.7713\n",
      "Best model updated at epoch 4 with validation loss 0.6073\n",
      "Best model updated at epoch 5 with validation loss 0.4329\n",
      "Best model updated at epoch 6 with validation loss 0.3327\n",
      "Best model updated at epoch 7 with validation loss 0.2484\n",
      "Best model updated at epoch 8 with validation loss 0.1099\n",
      "Epoch [10/100], Train Loss: 0.1084, Val Loss: -0.0528\n",
      "Best model updated at epoch 10 with validation loss -0.0528\n",
      "Best model updated at epoch 13 with validation loss -0.1984\n",
      "Best model updated at epoch 14 with validation loss -0.2087\n",
      "Best model updated at epoch 15 with validation loss -0.2525\n",
      "Best model updated at epoch 16 with validation loss -0.2707\n",
      "Best model updated at epoch 17 with validation loss -0.2856\n",
      "Best model updated at epoch 18 with validation loss -0.4104\n",
      "Epoch [20/100], Train Loss: -0.3871, Val Loss: -0.3947\n",
      "Best model updated at epoch 21 with validation loss -0.4785\n",
      "Best model updated at epoch 24 with validation loss -0.5510\n",
      "Best model updated at epoch 26 with validation loss -0.6213\n",
      "Best model updated at epoch 28 with validation loss -0.6339\n",
      "Epoch [30/100], Train Loss: -0.6809, Val Loss: -0.5876\n",
      "Best model updated at epoch 31 with validation loss -0.6774\n",
      "Best model updated at epoch 33 with validation loss -0.6904\n",
      "Best model updated at epoch 34 with validation loss -0.8018\n",
      "Best model updated at epoch 35 with validation loss -0.8131\n",
      "Best model updated at epoch 37 with validation loss -0.8367\n",
      "Best model updated at epoch 38 with validation loss -0.8978\n",
      "Epoch [40/100], Train Loss: -0.9407, Val Loss: -0.8471\n",
      "Best model updated at epoch 41 with validation loss -0.9484\n",
      "Best model updated at epoch 43 with validation loss -0.9810\n",
      "Best model updated at epoch 44 with validation loss -1.0263\n",
      "Best model updated at epoch 47 with validation loss -1.0462\n",
      "Best model updated at epoch 49 with validation loss -1.1624\n",
      "Epoch [50/100], Train Loss: -1.1435, Val Loss: -1.0570\n",
      "Best model updated at epoch 55 with validation loss -1.2592\n",
      "Epoch [60/100], Train Loss: -1.3542, Val Loss: -1.3432\n",
      "Best model updated at epoch 60 with validation loss -1.3432\n",
      "Best model updated at epoch 67 with validation loss -1.4243\n",
      "Best model updated at epoch 69 with validation loss -1.5733\n",
      "Epoch [70/100], Train Loss: -1.5317, Val Loss: -1.5233\n",
      "Best model updated at epoch 74 with validation loss -1.5937\n",
      "Best model updated at epoch 77 with validation loss -1.6301\n",
      "Best model updated at epoch 79 with validation loss -1.6742\n",
      "Epoch [80/100], Train Loss: -1.7030, Val Loss: -1.6377\n",
      "Best model updated at epoch 82 with validation loss -1.6877\n",
      "Best model updated at epoch 84 with validation loss -1.7081\n",
      "Best model updated at epoch 85 with validation loss -1.7175\n",
      "Best model updated at epoch 86 with validation loss -1.7184\n",
      "Best model updated at epoch 87 with validation loss -1.7306\n",
      "Best model updated at epoch 88 with validation loss -1.7346\n",
      "Best model updated at epoch 89 with validation loss -1.7369\n",
      "Epoch [90/100], Train Loss: -1.7638, Val Loss: -1.8092\n",
      "Best model updated at epoch 90 with validation loss -1.8092\n",
      "Best model updated at epoch 95 with validation loss -1.8953\n",
      "Epoch [100/100], Train Loss: -1.8641, Val Loss: -1.8824\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for x_seq, x_cal, y in train_loader:\n",
    "        x_seq = x_seq.to(device)\n",
    "        x_cal = x_cal.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pi, mu, sigma = model(x_seq, x_cal)\n",
    "        loss = mdn_loss(pi, mu, sigma, y)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * x_seq.size(0)\n",
    "    epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x_seq, x_cal, y in val_loader:\n",
    "            x_seq = x_seq.to(device)\n",
    "            x_cal = x_cal.to(device)\n",
    "            y = y.to(device)\n",
    "            pi, mu, sigma = model(x_seq, x_cal)\n",
    "            loss = mdn_loss(pi, mu, sigma, y)\n",
    "            running_val_loss += loss.item() * x_seq.size(0)\n",
    "    epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    \n",
    "    scheduler.step(epoch_val_loss)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n",
    "    \n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        checkpoint = {\n",
    "            'epoch': epoch+1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': epoch_val_loss\n",
    "        }\n",
    "        torch.save(checkpoint, 'best_mdn_checkpoint.pth')\n",
    "        print(f\"Best model updated at epoch {epoch+1} with validation loss {epoch_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared: 0.9491\n",
      "Test MAPE: 0.3406\n",
      "Test RMSE: 168429.0625\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_preds = []\n",
    "test_actuals = []\n",
    "with torch.no_grad():\n",
    "    for x_seq, x_cal, y in test_loader:\n",
    "        x_seq = x_seq.to(device)\n",
    "        x_cal = x_cal.to(device)\n",
    "        y = y.to(device)\n",
    "        pi, mu, sigma = model(x_seq, x_cal)\n",
    "        # Dự báo điểm: ta có thể sử dụng weighted sum của μ theo pi\n",
    "        pred = torch.sum(pi.unsqueeze(2) * mu, dim=1)  # (batch, output_dim)\n",
    "        test_preds.append(pred.cpu().numpy())\n",
    "        test_actuals.append(y.cpu().numpy())\n",
    "test_preds = np.concatenate(test_preds, axis=0)\n",
    "test_actuals = np.concatenate(test_actuals, axis=0)\n",
    "\n",
    "# Inverse transform nếu cần (giả sử scaler đã được fit trên target)\n",
    "test_preds_inv = scaler.inverse_transform(test_preds)\n",
    "test_actuals_inv = scaler.inverse_transform(test_actuals)\n",
    "\n",
    "r2 = r2_score(test_actuals_inv, test_preds_inv)\n",
    "mape = mean_absolute_percentage_error(test_actuals_inv, test_preds_inv)\n",
    "rmse = np.sqrt(mean_squared_error(test_actuals_inv, test_preds_inv))\n",
    "print(f\"Test R-squared: {r2:.4f}\")\n",
    "print(f\"Test MAPE: {mape:.4f}\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
